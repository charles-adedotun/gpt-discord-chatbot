import os
import logging
import openai
import asyncio

# Set the OpenAI API key and language model ID
try:
    openai.api_key = os.environ["OPENAI_API_KEY"]
except KeyError:
    logging.error("Please set the environment variable OPENAI_API_KEY to use the OpenAI API.")
model_id = 'gpt-3.5-turbo'

# Define the default system message and maximum number of tokens for the GPT-3.5 API call
system = 'You are Ï€GPT. You will make sure you always think through your responses step-by-step and reiterate till you are certain you did not make any mistakes. Do not make any assumptions.'
max_tokens = 1999

# Create a dictionary to store conversation history for each user
conversation_dict = {}

# Configure logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# Function to generate a response using the GPT-3.5 language model based on the conversation history so far
async def ChatGPT_conversation(conversation):
    """
    Generate a response using the GPT-3.5 language model based on the conversation history so far.

    Parameters:
    conversation (list): List of dictionaries representing the conversation history.

    Returns:
    list: Updated list of dictionaries representing the conversation history, with the new response added.
    """
    # Limit the conversation history to the last n messages (e.g. 8 messages)
    n = 8
    conversation = conversation[-n:]

    # Call the OpenAI API to generate a response based on the conversation history
    global response
    response = openai.ChatCompletion.create(
        model=model_id,
        max_tokens = max_tokens,
        messages=conversation
    )
    
    # Add the new response to the conversation history
    conversation.append({'role': response.choices[0].message.role, 'content': response.choices[0].message.content})
    
    # Log the response
    logging.info(f'Response generated: "{response.choices[0].message.content}"')
    
    return conversation

# Function to get a response from the chatbot given the user ID and message
async def get_response(user_id: str, message: str) -> str:
    """
    Get a response from the chatbot given the user ID and message.

    Parameters:
    user_id (str): The ID of the user who sent the message.
    message (str): The message sent by the user.

    Returns:
    str: The response generated by the chatbot.
    """
    # Check if the user has an existing conversation history, and create one if not
    global conversation_dict
    if user_id not in conversation_dict:
        conversation_dict[user_id] = [{'role': 'system', 'content': system}]
    
    # Add the user's message to the conversation history and generate a response using the GPT-3.5 model
    conversation = conversation_dict[user_id]
    conversation.append({'role': 'user', 'content': message})
    
    # Run the ChatGPT_conversation coroutine in the background using asyncio.create_task
    task = asyncio.create_task(ChatGPT_conversation(conversation))
    
    # Wait for the user to send their next message while the coroutine runs in the background
    while not task.done():
        await asyncio.sleep(0)
    
    # Get the latest GPT-3.5 response and store the updated conversation history for the user
    conversation = task.result()
    gpt_response = conversation[-1]['content'].strip()
    conversation_dict[user_id] = conversation
    
    # Check the API usage to see if the maximum token limit has been exceeded
    api_usage = response['usage']
    tokens_used = api_usage['total_tokens']
    
    # Log the response
    logging.info(f'Response sent to user {user_id}: "{gpt_response}"')
    
    if tokens_used > max_tokens:
        # If the maximum token limit has been exceeded, clear the conversation history for the user
        conversation_dict[user_id] = [{'role': 'system', 'content': system}]
        return f'`{tokens_used} tokens used. Conversation history has now been cleared. Last response:\n{gpt_response}`'
    else:
        return gpt_response
